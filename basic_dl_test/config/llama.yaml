# Logging related
batch_logging_output_inc: 100

# GPU related
gpu_ids: [4,5] # [-1] will set CPU for use
master_address: 'localhost'
master_port: '65531'
use_mixed_precision: True

# Hyperparameters
epochs: 3
learning_rate: .00002

# Dataset & dataloader related
max_length: 512
batch_size: 16
num_labels: 2
num_workers: 4

# Model specification
model_name: 'llama-3.1-8b' # Change to 'llama-3.1-70b' for the larger model
